{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from pyproj import Transformer\n",
    "from pyproj import CRS, Proj\n",
    "\n",
    "from osgeo import gdal \n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generation data\n",
    "path = os.getcwd() + \"\\\\Raw_Spatial_Data\\\\Gen 2016-2023_vs edit.xlsx\"\n",
    "gen_data_wet = pd.read_excel(path,\"2022\")\n",
    "gen_data_dry = pd.read_excel(path,\"2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the plant data (head, location, etc.)\n",
    "path = os.getcwd() + \"\\\\Raw_Spatial_Data\\\\19.7.2024-NEW UPDATED_Data_lao_231223_NPP_coordinate.xlsx\"\n",
    "data = pd.read_excel(path,'NPDP power plant info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREP OF PLANT DATA\n",
    "data = data[['SNo', 'East E', 'North N', 'Status', 'PP name', 'New Ose_Name','Fuel Type',\n",
    "       'Province', 'Region', 'Total capacity (MW)',\n",
    "       'Domestic Capacity (MW)', 'Export Capacity (MW)',\n",
    "       'Expected Generation (GWh)',\n",
    "       'total theoretical possible generation (local) GWh', 'COD (Year)',\n",
    "       'Exporting country country', 'Head Hydraulic (m)']]\n",
    "\n",
    "data['East E'] = pd.to_numeric(data['East E'], errors='coerce')\n",
    "data['North N'] = pd.to_numeric(data['North N'], errors='coerce')\n",
    "\n",
    "data = data.dropna(subset=['East E', 'North N'])\n",
    "\n",
    "transformer = Transformer.from_crs(\"epsg:32648\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "def convert_coordinates(easting, northing):\n",
    "    longitude, latitude = transformer.transform(easting, northing)\n",
    "    return latitude, longitude\n",
    "\n",
    "converted_coords = data.apply(\n",
    "    lambda row: convert_coordinates(row['East E'], row['North N']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data = data.copy()\n",
    "data[['Latitude', 'Longitude']] = pd.DataFrame(converted_coords.tolist(), index=data.index)\n",
    "data[['East E','North N','Latitude','Longitude']]\n",
    "\n",
    "data = data[['SNo', 'New Ose_Name', 'Status','Fuel Type','Latitude','Longitude','Total capacity (MW)','Domestic Capacity (MW)',\n",
    "             'Expected Generation (GWh)','total theoretical possible generation (local) GWh',\n",
    "             'COD (Year)','Head Hydraulic (m)']]\n",
    "data = data.rename(columns={\"Total capacity (MW)\": \"capacity\",\n",
    "                                   \"COD (Year)\": \"COD\",\n",
    "                                   \"Head Hydraulic (m)\": \"head\"})\n",
    "\n",
    "data = data[data['Fuel Type'].isin(['Run - Off', 'Reservoir '])]\n",
    "data['capacity'] = pd.to_numeric(data['capacity'], errors='raise')\n",
    "\n",
    "data['Fuel Type'] = data['Fuel Type'].str.replace(\"Reservoir \", \"Reservoir\")\n",
    "data.to_excel(\"hydropower_list_seasonal.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrological Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate Reference Systems\n",
    "wgs84 = CRS(\"EPSG:4326\")\n",
    "merc = CRS(\"EPSG:3395\")\n",
    "merc_pro = Proj(\"EPSG:3395\")\n",
    "\n",
    "class LocalHydroNetwork:\n",
    "    def __init__(self, dem_path, flow_path, flow_acc_path):\n",
    "        self.dem = rasterio.open(dem_path)\n",
    "        self.flow = rasterio.open(flow_path)\n",
    "        self.flow_acc = rasterio.open(flow_acc_path)\n",
    "\n",
    "    def create_local_network(self, point, buffer=0.005):\n",
    "        minx, miny = point.x - buffer, point.y - buffer\n",
    "        maxx, maxy = point.x + buffer, point.y + buffer\n",
    "\n",
    "        window = rasterio.windows.from_bounds(minx, miny, maxx, maxy, self.dem.transform)\n",
    "        dem_local = self.dem.read(1, window=window)\n",
    "        flow_local = self.flow.read(1, window=window)\n",
    "        flow_acc_local = self.flow_acc.read(1, window=window)\n",
    "\n",
    "        transform = rasterio.windows.transform(window, self.dem.transform)\n",
    "\n",
    "        nodes, arcs = self._extract_nodes_arcs(dem_local, flow_local, flow_acc_local, transform)\n",
    "        return nodes, arcs\n",
    "\n",
    "    def _extract_nodes_arcs(self, dem_local, flow_local, flow_acc_local, transform):\n",
    "        nodes = []\n",
    "        arcs = []\n",
    "        height, width = dem_local.shape\n",
    "        node_index_map = {}\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                x, y = transform * (j, i)\n",
    "                elevation = dem_local[i, j]\n",
    "                flow_dir = flow_local[i, j]\n",
    "                flow_acc = flow_acc_local[i, j]\n",
    "\n",
    "                current_node = (i, j)\n",
    "                if current_node not in node_index_map:\n",
    "                    node_id = len(nodes)\n",
    "                    node = {\n",
    "                        'id': node_id,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'elevation': elevation,\n",
    "                        'flow_acc': flow_acc,\n",
    "                        'arcs': []\n",
    "                    }\n",
    "                    nodes.append(node)\n",
    "                    node_index_map[current_node] = node_id\n",
    "                else:\n",
    "                    node_id = node_index_map[current_node]\n",
    "\n",
    "                if flow_dir > 0:\n",
    "                    next_i, next_j = self._flow_direction_to_indices(i, j, flow_dir)\n",
    "                    if 0 <= next_i < height and 0 <= next_j < width:\n",
    "                        next_node = (next_i, next_j)\n",
    "                        if next_node not in node_index_map:\n",
    "                            next_node_id = len(nodes)\n",
    "                            next_x, next_y = transform * (next_j, next_i)\n",
    "                            next_elevation = dem_local[next_i, next_j]\n",
    "                            next_flow_acc = flow_acc_local[next_i, next_j]\n",
    "\n",
    "                            next_node_data = {\n",
    "                                'id': next_node_id,\n",
    "                                'x': next_x,\n",
    "                                'y': next_y,\n",
    "                                'elevation': next_elevation,\n",
    "                                'flow_acc': next_flow_acc,\n",
    "                                'arcs': []\n",
    "                            }\n",
    "                            nodes.append(next_node_data)\n",
    "                            node_index_map[next_node] = next_node_id\n",
    "                        else:\n",
    "                            next_node_id = node_index_map[next_node]\n",
    "\n",
    "                        arc = {\n",
    "                            'start_node': node_id,\n",
    "                            'end_node': next_node_id,\n",
    "                            'length': np.hypot(next_i - i, next_j - j)\n",
    "                        }\n",
    "                        nodes[node_id]['arcs'].append(arc)\n",
    "                        arcs.append(arc)\n",
    "\n",
    "        return nodes, arcs\n",
    "\n",
    "    def _flow_direction_to_indices(self, i, j, direction):\n",
    "        if direction == 1:  # East\n",
    "            return i, j + 1\n",
    "        elif direction == 2:  # Southeast\n",
    "            return i + 1, j + 1\n",
    "        elif direction == 4:  # South\n",
    "            return i + 1, j\n",
    "        elif direction == 8:  # Southwest\n",
    "            return i + 1, j - 1\n",
    "        elif direction == 16:  # West\n",
    "            return i, j - 1\n",
    "        elif direction == 32:  # Northwest\n",
    "            return i - 1, j - 1\n",
    "        elif direction == 64:  # North\n",
    "            return i - 1, j\n",
    "        elif direction == 128:  # Northeast\n",
    "            return i - 1, j + 1\n",
    "        else:\n",
    "            return i, j  # No direction\n",
    "\n",
    "    def calculate_head(self, nodes, arcs):\n",
    "        max_head = 0\n",
    "        for arc in arcs:\n",
    "            start_node = nodes[arc['start_node']]\n",
    "            end_node = nodes[arc['end_node']]\n",
    "            head = start_node['elevation'] - end_node['elevation']\n",
    "            if head > max_head:\n",
    "                max_head = head\n",
    "        return max_head\n",
    "\n",
    "    def process_hydropower_plants(self, df, buffer):\n",
    "        df['head_calculated'] = pd.NA\n",
    "        for index, row in df.iterrows():\n",
    "            point = Point(row['Longitude'], row['Latitude'])\n",
    "            nodes, arcs = self.create_local_network(point, buffer)\n",
    "            head = self.calculate_head(nodes, arcs)\n",
    "            df.at[index, 'head_calculated'] = head\n",
    "        df['head_difference'] = df['head'] - df['head_calculated']\n",
    "        return df\n",
    "\n",
    "    def optimize_buffer(self, df, buffer_range):\n",
    "        best_mae = float('inf')\n",
    "        best_std = float('inf')\n",
    "        best_buffer = None\n",
    "        best_df = None\n",
    "        \n",
    "        for buffer in buffer_range:\n",
    "            df_processed = self.process_hydropower_plants(df.copy(), buffer)\n",
    "            mae = df_processed['head_difference'].abs().mean()\n",
    "            std = df_processed['head_difference'].std()\n",
    "            if mae + std < best_mae + best_std:\n",
    "                best_mae = mae\n",
    "                best_std = std\n",
    "                best_buffer = buffer\n",
    "                best_df = df_processed\n",
    "        \n",
    "        print(f\"Optimal Buffer: {best_buffer}\")\n",
    "        print(f\"Mean Absolute Error: {best_mae}\")\n",
    "        print(f\"Standard Deviation: {best_std}\")\n",
    "        \n",
    "        return best_df, best_buffer, best_mae, best_std\n",
    "\n",
    "    def optimize_for_fuel_types(self, df, buffer_range):\n",
    "        # Optimize only for rows with existing head values\n",
    "        reservoir_df = df[df['Fuel Type'] == 'Reservoir'].dropna(subset=['head']).copy()\n",
    "        runoff_df = df[df['Fuel Type'] == 'Run - Off'].dropna(subset=['head']).copy()\n",
    "\n",
    "        print(\"\\nOptimizing for Reservoir plants...\")\n",
    "        optimized_reservoir_df, optimal_reservoir_buffer, reservoir_mae, reservoir_std = self.optimize_buffer(reservoir_df, buffer_range)\n",
    "        \n",
    "        print(\"\\nOptimizing for Run - Off plants...\")\n",
    "        optimized_runoff_df, optimal_runoff_buffer, runoff_mae, runoff_std = self.optimize_buffer(runoff_df, buffer_range)\n",
    "\n",
    "        return {\n",
    "            'reservoir': {\n",
    "                'df': optimized_reservoir_df, \n",
    "                'buffer': optimal_reservoir_buffer, \n",
    "                'mae': reservoir_mae, \n",
    "                'std': reservoir_std\n",
    "            },\n",
    "            'runoff': {\n",
    "                'df': optimized_runoff_df, \n",
    "                'buffer': optimal_runoff_buffer, \n",
    "                'mae': runoff_mae, \n",
    "                'std': runoff_std\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def calculate_and_fill_missing_heads(self, df, reservoir_buffer, runoff_buffer):\n",
    "        # Process all rows with the optimized buffer sizes\n",
    "        df_reservoir = self.process_hydropower_plants(df[df['Fuel Type'] == 'Reservoir'].copy(), reservoir_buffer)\n",
    "        df_runoff = self.process_hydropower_plants(df[df['Fuel Type'] == 'Run - Off'].copy(), runoff_buffer)\n",
    "\n",
    "        # Combine results back into the original DataFrame\n",
    "        df_combined = pd.concat([df_reservoir, df_runoff])\n",
    "\n",
    "        # Fill missing head values in the original DataFrame\n",
    "        for index, row in df_combined.iterrows():\n",
    "            if pd.isna(df.at[index, 'head']):\n",
    "                df.at[index, 'head'] = df_combined.at[index, 'head_calculated']\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing for Reservoir plants...\n",
      "Optimal Buffer: 0.003385\n",
      "Mean Absolute Error: 26.0828125\n",
      "Standard Deviation: 29.08527294557416\n",
      "\n",
      "Optimizing for Run - Off plants...\n",
      "Optimal Buffer: 0.003195\n",
      "Mean Absolute Error: 45.85\n",
      "Standard Deviation: 84.40090732862258\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "dem_path = path + \"\\\\Raw_Spatial_Data\\\\hydro_data\\\\dem_con_asia.tif\"\n",
    "flow_path = path + \"\\\\Raw_Spatial_Data\\\\hydro_data\\\\flow_asia.tif\"\n",
    "flow_acc_path = path + \"\\Raw_Spatial_Data\\\\hydro_data\\\\as_acc_3s.tif\"\n",
    "xlsx_file = \"hydropower_list_seasonal.xlsx\"\n",
    "\n",
    "buffer_range = np.linspace(0.00025, 0.005, 101)\n",
    "hydro_network = LocalHydroNetwork(dem_path, flow_path, flow_acc_path)\n",
    "\n",
    "df = pd.read_excel(xlsx_file)\n",
    "results = hydro_network.optimize_for_fuel_types(df, buffer_range)\n",
    "\n",
    "plant_data = hydro_network.calculate_and_fill_missing_heads(df, results['reservoir']['buffer'], results['runoff']['buffer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_wet = pd.merge(gen_data_wet, plant_data, left_on='OSeMOSYS tech', right_on='New Ose_Name', how='inner')\n",
    "merged_data_wet = pd.merge(gen_data_dry, plant_data, left_on='OSeMOSYS tech', right_on='New Ose_Name', how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoh2-data-prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
